{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import simplejson\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import threading\n",
    "\n",
    "import utils.train_utils as train_utils\n",
    "import utils.googlenet_load as googlenet_load\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "import time\n",
    "import tensorflow.contrib.slim as slim\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import array_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@ops.RegisterGradient('Hungarian')\n",
    "def _hungarian_grad(op, *args):\n",
    "    return map(array_ops.zeros_like, op.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def enqueue_thread(sess, coord, enqueue, gen, phase):\n",
    "    while not coord.should_stop():\n",
    "        data_gen = gen.next()\n",
    "        image = data_gen['image']\n",
    "        confs = data_gen['confs']\n",
    "        boxes = data_gen['boxes']\n",
    "        sess.run(enqueue, feed_dict={x_in[phase]:image, box_in[phase]:boxes, conf_in[phase]:confs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_lstm(x, H, reuse):\n",
    "    '''\n",
    "    Building LSTM layers\n",
    "    '''\n",
    "    rnn_len = H['rnn_len']\n",
    "    num_states = H['num_states']\n",
    "    num_lstm_layers = H['num_lstm_layers']\n",
    "    grid_height = H['grid_height']\n",
    "    grid_width = H['grid_width']\n",
    "    grid_size = grid_height*grid_width\n",
    "    batch_size = H['batch_size']\n",
    "    outer_size = batch_size*grid_size\n",
    "    \n",
    "    lstm_cells = rnn.MultiRNNCell(\n",
    "        cells=[rnn.BasicLSTMCell(num_units=num_states,reuse=reuse) for _ in range(num_lstm_layers)])\n",
    "    \n",
    "    state = lstm_cells.zero_state(batch_size=outer_size, dtype=tf.float32)\n",
    "    \n",
    "    lstm_outputs = []\n",
    "    \n",
    "    initializer = tf.random_uniform_initializer(-0.1, 0.1)\n",
    "    with tf.variable_scope('lstm', reuse=reuse, initializer=initializer):\n",
    "        for i in range(rnn_len):\n",
    "            if i>0: tf.get_variable_scope().reuse_variables()\n",
    "            lstm_out, state = lstm_cells(x, state)\n",
    "            lstm_outputs.append(lstm_out)\n",
    "    return lstm_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_pred(H, x_in, phase):\n",
    "    '''\n",
    "    Building the feedforward NN for both training and test\n",
    "    '''\n",
    "    grid_height = H['grid_height']\n",
    "    grid_width = H['grid_width']\n",
    "    grid_size = grid_height*grid_width\n",
    "    batch_size = H['batch_size']\n",
    "    outer_size = batch_size*grid_size\n",
    "    later_feat_channels = H['later_feat_channels']\n",
    "    num_states = H['num_states']\n",
    "\n",
    "    batch_size = H['batch_size']\n",
    "    \n",
    "    reuse = {'train': False, 'test': True}[phase]\n",
    "    is_training = {'train': True, 'test': False}[phase]\n",
    "\n",
    "    x_in -= 117\n",
    "    feat_5c, feat_3b = googlenet_load.model(x=x_in, is_training=is_training, H=H, reuse=reuse)\n",
    "\n",
    "    scaling_factor = 0.01\n",
    "    lstm_input = tf.reshape(feat_5c*scaling_factor, shape=[outer_size, later_feat_channels])\n",
    "\n",
    "    lstm_outputs = build_lstm(lstm_input, H, reuse)\n",
    "\n",
    "    initializer = tf.random_uniform_initializer(-0.1, 0.1)\n",
    "    pred_boxes_c, pred_logits_c = [], []\n",
    "    with tf.variable_scope('decoder', reuse=reuse, initializer=initializer):\n",
    "        for i in range(rnn_len):\n",
    "            box_weight = tf.get_variable(dtype=tf.float32,name='box_weight_%i' %i, shape=[num_states, 4])\n",
    "            logit_weight = tf.get_variable(dtype=tf.float32,name='conf_weight_%i' %i, shape=[num_states, 2])\n",
    "            pred_box = tf.matmul(lstm_outputs[i], box_weight)*50.\n",
    "            pred_logit = tf.matmul(lstm_outputs[i], logit_weight)\n",
    "            pred_box_r = tf.reshape(pred_box, shape=[outer_size,1,4])\n",
    "            pred_logit_r = tf.reshape(pred_logit, shape=[outer_size,1,2])\n",
    "            pred_boxes_c.append(pred_box_r)\n",
    "            pred_logits_c.append(pred_logit_r)\n",
    "        pred_boxes = tf.concat(values=pred_boxes_c, axis=1)\n",
    "        pred_logits = tf.concat(values=pred_logits_c, axis=1)\n",
    "        pred_confs = tf.nn.softmax(logits=pred_logits)\n",
    "        \n",
    "    return pred_boxes, pred_logits, pred_confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_loss(H, q):\n",
    "    '''\n",
    "    Building the feedforward NN for both training and test, using build_pred\n",
    "    And then:\n",
    "    Building the loss function\n",
    "    '''\n",
    "    grid_height = H['grid_height']\n",
    "    grid_width = H['grid_width']\n",
    "    grid_size = grid_height*grid_width\n",
    "    batch_size = H['batch_size']\n",
    "    outer_size = batch_size*grid_size\n",
    "    rnn_len = H['rnn_len']\n",
    "    hungarian_iou = H['hungarian_iou']\n",
    "    conf_weight = H['conf_weight']\n",
    "    box_weight = H['box_weight']\n",
    "    \n",
    "    pred_boxes, pred_logits, pred_confs, loss_box, loss_conf, accuracy, loss = {}, {}, {}, {}, {}, {}, {}\n",
    "    hungarian_module = tf.load_op_library('utils/hungarian/hungarian.so')\n",
    "\n",
    "    for phase in ['train' ,'test']:\n",
    "        x_in, box_in ,conf_in = q[phase].dequeue_many(batch_size)\n",
    "        \n",
    "        flag_in = tf.arg_max(conf_in, dimension=-1)\n",
    "        \n",
    "        box_r = tf.reshape(box_in, shape=[outer_size, rnn_len, 4])\n",
    "        flag_r = tf.cast(tf.reshape(flag_in, shape=[outer_size, rnn_len]), tf.int32)\n",
    "\n",
    "        pred_boxes[phase], pred_logits[phase], pred_confs[phase] = build_pred(H, x_in, phase)\n",
    "        # classes is the reordered correct label\n",
    "        # perm_truth is the reordered correct boxes\n",
    "        # pred_mask is the mask for the predicted boxes\n",
    "        assignments, classes, perm_truth, pred_mask = hungarian_module.hungarian(\n",
    "            pred_boxes[phase], box_r, flag_r, hungarian_iou)\n",
    "        true_class = tf.cast(tf.greater(classes, 0), dtype=tf.int32)\n",
    "        loss_conf[phase] = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=pred_logits[phase], labels=true_class))*conf_weight\n",
    "        residual = tf.abs(perm_truth-pred_boxes[phase]*pred_mask)\n",
    "        loss_box[phase] = tf.reduce_mean(residual)*box_weight\n",
    "        loss[phase] = loss_box[phase]+loss_conf[phase]\n",
    "        pred_flag = tf.cast(tf.arg_max(pred_logits[phase], dimension=-1), tf.int32)\n",
    "        accuracy[phase] = tf.reduce_mean(tf.cast(tf.equal(flag_r, pred_flag),tf.float32))\n",
    "    return pred_boxes, pred_confs, loss, loss_box, loss_conf, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build(H, q):\n",
    "    '''\n",
    "    Building the train_op, summary\n",
    "    '''\n",
    "    clip_norm = H['clip_norm']\n",
    "    log_dir = 'logdir'\n",
    "    pred_boxes, pred_confs, loss, loss_box, loss_conf, accuracy = build_loss(H, q)\n",
    "    \n",
    "    # train_op\n",
    "    lr = tf.placeholder(tf.float32, shape=[])\n",
    "    opt = tf.train.RMSPropOptimizer(decay=0.9,learning_rate=lr, epsilon=0.0001)\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads = tf.gradients(loss['train'], tvars)\n",
    "    grads, norm = tf.clip_by_global_norm(grads, clip_norm)\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = opt.apply_gradients(zip(grads, tvars), global_step=global_step)\n",
    "    \n",
    "    # building the summary\n",
    "    for phase in ['train', 'test']:\n",
    "        tf.summary.scalar('%s/loss'%phase, loss[phase])\n",
    "        tf.summary.scalar('%s/accuracy'%phase, accuracy[phase])\n",
    "    \n",
    "    summary_op = tf.summary.merge_all()\n",
    "    return train_op, summary_op, global_step, loss, accuracy,lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hypes = 'hypes/lstm_cnn.json'\n",
    "with open(hypes) as f:\n",
    "    H = simplejson.load(f)\n",
    "image_height = H['image_height']\n",
    "image_width = H['image_width']\n",
    "queue_size = H['queue_size']\n",
    "rnn_len = H['rnn_len']\n",
    "num_classes = H['num_classes']\n",
    "grid_width = H['grid_width']\n",
    "grid_height = H['grid_height']\n",
    "grid_size = grid_height*grid_width\n",
    "batch_size = H['batch_size']\n",
    "clip_norm = H['clip_norm']\n",
    "max_iter = H['max_iter']\n",
    "display_iter = H['display_iter']\n",
    "learning_rate = H['learning_rate']\n",
    "lr_step = H['lr_step']\n",
    "save_iter = H['save_iter']\n",
    "log_dir = H['log_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queue, enqueue_op, x_in, box_in, conf_in = {}, {}, {}, {}, {}\n",
    "shape = ([image_height, image_width, 3],\n",
    "         [grid_size, rnn_len, 4],\n",
    "         [grid_size, rnn_len, num_classes]\n",
    "        )\n",
    "for phase in ['train', 'test']:\n",
    "    x_in[phase] = tf.placeholder(tf.float32)\n",
    "    box_in[phase] = tf.placeholder(tf.float32)\n",
    "    conf_in[phase] = tf.placeholder(tf.float32)\n",
    "    queue[phase] = tf.FIFOQueue(capacity=queue_size,\n",
    "                                shapes=shape,\n",
    "                                dtypes=(tf.float32, tf.float32, tf.float32)\n",
    "                               )\n",
    "    enqueue_op[phase] = queue[phase].enqueue((x_in[phase], box_in[phase], conf_in[phase]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_op, summary_op, global_step, loss, accuracy,lr = build(H, queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionV1/Conv2d_1a_7x7/weights:0\n",
      "InceptionV1/Conv2d_1a_7x7/BatchNorm/beta:0\n",
      "InceptionV1/Conv2d_1a_7x7/BatchNorm/gamma:0\n",
      "InceptionV1/Conv2d_2b_1x1/weights:0\n",
      "InceptionV1/Conv2d_2b_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Conv2d_2b_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Conv2d_2c_3x3/weights:0\n",
      "InceptionV1/Conv2d_2c_3x3/BatchNorm/beta:0\n",
      "InceptionV1/Conv2d_2c_3x3/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_3b/Branch_0/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_3b/Branch_0/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_3b/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_3b/Branch_1/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_3b/Branch_1/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_3b/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_3b/Branch_1/Conv2d_0b_3x3/weights:0\n",
      "InceptionV1/Mixed_3b/Branch_1/Conv2d_0b_3x3/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_3b/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_3b/Branch_2/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_3b/Branch_2/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_3b/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_3b/Branch_2/Conv2d_0b_3x3/weights:0\n",
      "InceptionV1/Mixed_3b/Branch_2/Conv2d_0b_3x3/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_3b/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_3b/Branch_3/Conv2d_0b_1x1/weights:0\n",
      "InceptionV1/Mixed_3b/Branch_3/Conv2d_0b_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_3b/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_3c/Branch_0/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_3c/Branch_0/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_3c/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_3c/Branch_1/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_3c/Branch_1/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_3c/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_3c/Branch_1/Conv2d_0b_3x3/weights:0\n",
      "InceptionV1/Mixed_3c/Branch_1/Conv2d_0b_3x3/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_3c/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_3c/Branch_2/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_3c/Branch_2/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_3c/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_3c/Branch_2/Conv2d_0b_3x3/weights:0\n",
      "InceptionV1/Mixed_3c/Branch_2/Conv2d_0b_3x3/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_3c/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_3c/Branch_3/Conv2d_0b_1x1/weights:0\n",
      "InceptionV1/Mixed_3c/Branch_3/Conv2d_0b_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_3c/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4b/Branch_0/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_4b/Branch_0/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4b/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4b/Branch_1/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_4b/Branch_1/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4b/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4b/Branch_1/Conv2d_0b_3x3/weights:0\n",
      "InceptionV1/Mixed_4b/Branch_1/Conv2d_0b_3x3/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4b/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4b/Branch_2/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_4b/Branch_2/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4b/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4b/Branch_2/Conv2d_0b_3x3/weights:0\n",
      "InceptionV1/Mixed_4b/Branch_2/Conv2d_0b_3x3/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4b/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4b/Branch_3/Conv2d_0b_1x1/weights:0\n",
      "InceptionV1/Mixed_4b/Branch_3/Conv2d_0b_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4b/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4c/Branch_0/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_4c/Branch_0/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4c/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4c/Branch_1/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_4c/Branch_1/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4c/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4c/Branch_1/Conv2d_0b_3x3/weights:0\n",
      "InceptionV1/Mixed_4c/Branch_1/Conv2d_0b_3x3/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4c/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4c/Branch_2/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_4c/Branch_2/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4c/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4c/Branch_2/Conv2d_0b_3x3/weights:0\n",
      "InceptionV1/Mixed_4c/Branch_2/Conv2d_0b_3x3/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4c/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4c/Branch_3/Conv2d_0b_1x1/weights:0\n",
      "InceptionV1/Mixed_4c/Branch_3/Conv2d_0b_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4c/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4d/Branch_0/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_4d/Branch_0/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4d/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4d/Branch_1/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_4d/Branch_1/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4d/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4d/Branch_1/Conv2d_0b_3x3/weights:0\n",
      "InceptionV1/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4d/Branch_2/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_4d/Branch_2/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4d/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4d/Branch_2/Conv2d_0b_3x3/weights:0\n",
      "InceptionV1/Mixed_4d/Branch_2/Conv2d_0b_3x3/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4d/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4d/Branch_3/Conv2d_0b_1x1/weights:0\n",
      "InceptionV1/Mixed_4d/Branch_3/Conv2d_0b_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4d/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4e/Branch_0/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_4e/Branch_0/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4e/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4e/Branch_1/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_4e/Branch_1/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4e/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4e/Branch_1/Conv2d_0b_3x3/weights:0\n",
      "InceptionV1/Mixed_4e/Branch_1/Conv2d_0b_3x3/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4e/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4e/Branch_2/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_4e/Branch_2/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4e/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4e/Branch_2/Conv2d_0b_3x3/weights:0\n",
      "InceptionV1/Mixed_4e/Branch_2/Conv2d_0b_3x3/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4e/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4e/Branch_3/Conv2d_0b_1x1/weights:0\n",
      "InceptionV1/Mixed_4e/Branch_3/Conv2d_0b_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4e/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4f/Branch_0/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_4f/Branch_0/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4f/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4f/Branch_1/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_4f/Branch_1/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4f/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4f/Branch_1/Conv2d_0b_3x3/weights:0\n",
      "InceptionV1/Mixed_4f/Branch_1/Conv2d_0b_3x3/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4f/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4f/Branch_2/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_4f/Branch_2/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4f/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4f/Branch_2/Conv2d_0b_3x3/weights:0\n",
      "InceptionV1/Mixed_4f/Branch_2/Conv2d_0b_3x3/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4f/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_4f/Branch_3/Conv2d_0b_1x1/weights:0\n",
      "InceptionV1/Mixed_4f/Branch_3/Conv2d_0b_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_4f/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_5b/Branch_0/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_5b/Branch_1/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_5b/Branch_1/Conv2d_0b_3x3/weights:0\n",
      "InceptionV1/Mixed_5b/Branch_1/Conv2d_0b_3x3/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_5b/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_5b/Branch_2/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_5b/Branch_2/Conv2d_0a_3x3/weights:0\n",
      "InceptionV1/Mixed_5b/Branch_2/Conv2d_0a_3x3/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_5b/Branch_2/Conv2d_0a_3x3/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_5b/Branch_3/Conv2d_0b_1x1/weights:0\n",
      "InceptionV1/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_5c/Branch_0/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_5c/Branch_1/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_5c/Branch_1/Conv2d_0b_3x3/weights:0\n",
      "InceptionV1/Mixed_5c/Branch_1/Conv2d_0b_3x3/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_5c/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights:0\n",
      "InceptionV1/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_5c/Branch_2/Conv2d_0b_3x3/weights:0\n",
      "InceptionV1/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma:0\n",
      "InceptionV1/Mixed_5c/Branch_3/Conv2d_0b_1x1/weights:0\n",
      "InceptionV1/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm/beta:0\n",
      "InceptionV1/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma:0\n",
      "InceptionV1/Logits/Conv2d_0c_1x1/weights:0\n",
      "InceptionV1/Logits/Conv2d_0c_1x1/biases:0\n",
      "lstm/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0\n",
      "lstm/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0\n",
      "lstm/multi_rnn_cell/cell_1/basic_lstm_cell/weights:0\n",
      "lstm/multi_rnn_cell/cell_1/basic_lstm_cell/biases:0\n",
      "decoder/box_weight_0:0\n",
      "decoder/conf_weight_0:0\n",
      "decoder/box_weight_1:0\n",
      "decoder/conf_weight_1:0\n",
      "decoder/box_weight_2:0\n",
      "decoder/conf_weight_2:0\n",
      "decoder/box_weight_3:0\n",
      "decoder/conf_weight_3:0\n",
      "decoder/box_weight_4:0\n",
      "decoder/conf_weight_4:0\n"
     ]
    }
   ],
   "source": [
    "for ops in tf.trainable_variables(): print ops.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable InceptionV1/Mixed_3c/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4f/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4e/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4b/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_3b/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4c/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4f/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4c/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Conv2d_1a_7x7/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4c/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_3c/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4f/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4d/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_5b/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_3b/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4f/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4e/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4b/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4e/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4d/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4f/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4c/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Conv2d_2c_3x3/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4c/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4b/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_3c/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_3b/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Conv2d_2b_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_3b/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4d/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4b/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4d/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4f/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4c/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_3c/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_3c/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_5b/Branch_2/Conv2d_0a_3x3/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4b/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4e/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4d/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4e/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4e/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_3b/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_5c/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_3c/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_4b/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV1/Mixed_3b/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma missing in checkpoint data/inception_v1.ckpt\n",
      "INFO:tensorflow:Restoring parameters from data/inception_v1.ckpt\n",
      "Step: 0 lr: 0.001000 Train loss: 0.72 Test accuracy: 35.5 Time/image (ms) 0.0\n",
      "Step: 50 lr: 0.001000 Train loss: 0.71 Test accuracy: 97.2 Time/image (ms) 3550.6\n",
      "Step: 100 lr: 0.001000 Train loss: 0.54 Test accuracy: 99.0 Time/image (ms) 3298.3\n",
      "Step: 150 lr: 0.001000 Train loss: 0.28 Test accuracy: 99.0 Time/image (ms) 29147.9\n",
      "Step: 200 lr: 0.001000 Train loss: 0.20 Test accuracy: 99.3 Time/image (ms) 3571.2\n",
      "Step: 250 lr: 0.001000 Train loss: 0.16 Test accuracy: 96.9 Time/image (ms) 3618.1\n",
      "Step: 300 lr: 0.001000 Train loss: 0.12 Test accuracy: 97.8 Time/image (ms) 3480.7\n",
      "Step: 350 lr: 0.001000 Train loss: 0.12 Test accuracy: 99.4 Time/image (ms) 3314.3\n",
      "Step: 400 lr: 0.001000 Train loss: 0.07 Test accuracy: 98.0 Time/image (ms) 44961.6\n",
      "Step: 450 lr: 0.001000 Train loss: 0.06 Test accuracy: 99.1 Time/image (ms) 10118.3\n",
      "Step: 500 lr: 0.001000 Train loss: 0.05 Test accuracy: 98.2 Time/image (ms) 3343.0\n",
      "Step: 550 lr: 0.001000 Train loss: 0.11 Test accuracy: 97.1 Time/image (ms) 14426.0\n",
      "Step: 600 lr: 0.001000 Train loss: 0.07 Test accuracy: 98.4 Time/image (ms) 30196.8\n",
      "Step: 650 lr: 0.001000 Train loss: 0.09 Test accuracy: 98.3 Time/image (ms) 149723.5\n",
      "Step: 700 lr: 0.001000 Train loss: 0.11 Test accuracy: 98.4 Time/image (ms) 3347.5\n",
      "Step: 750 lr: 0.001000 Train loss: 0.05 Test accuracy: 97.6 Time/image (ms) 12342.4\n",
      "Step: 800 lr: 0.001000 Train loss: 0.07 Test accuracy: 99.4 Time/image (ms) 14414.2\n",
      "Step: 850 lr: 0.001000 Train loss: 0.11 Test accuracy: 98.7 Time/image (ms) 4859.3\n",
      "Step: 900 lr: 0.001000 Train loss: 0.13 Test accuracy: 98.3 Time/image (ms) 4127.2\n",
      "Step: 950 lr: 0.001000 Train loss: 0.09 Test accuracy: 99.1 Time/image (ms) 3339.1\n",
      "Step: 1000 lr: 0.001000 Train loss: 0.06 Test accuracy: 98.5 Time/image (ms) 3310.7\n",
      "Step: 1050 lr: 0.001000 Train loss: 0.08 Test accuracy: 98.8 Time/image (ms) 3360.1\n",
      "Step: 1100 lr: 0.001000 Train loss: 0.12 Test accuracy: 98.6 Time/image (ms) 3468.6\n",
      "Step: 1150 lr: 0.001000 Train loss: 0.10 Test accuracy: 98.8 Time/image (ms) 3383.5\n",
      "Step: 1200 lr: 0.001000 Train loss: 0.10 Test accuracy: 97.9 Time/image (ms) 3369.9\n",
      "Step: 1250 lr: 0.001000 Train loss: 0.06 Test accuracy: 98.7 Time/image (ms) 3228.4\n",
      "Step: 1300 lr: 0.001000 Train loss: 0.06 Test accuracy: 99.5 Time/image (ms) 5703.0\n",
      "Step: 1350 lr: 0.001000 Train loss: 0.12 Test accuracy: 99.2 Time/image (ms) 3282.6\n",
      "Step: 1400 lr: 0.001000 Train loss: 0.15 Test accuracy: 97.9 Time/image (ms) 3328.4\n",
      "Step: 1450 lr: 0.001000 Train loss: 0.08 Test accuracy: 99.2 Time/image (ms) 3480.3\n",
      "Step: 1500 lr: 0.001000 Train loss: 0.10 Test accuracy: 99.0 Time/image (ms) 3432.3\n",
      "Step: 1550 lr: 0.001000 Train loss: 0.03 Test accuracy: 99.1 Time/image (ms) 3362.8\n",
      "Step: 1600 lr: 0.001000 Train loss: 0.05 Test accuracy: 99.1 Time/image (ms) 3564.6\n",
      "Step: 1650 lr: 0.001000 Train loss: 0.10 Test accuracy: 98.9 Time/image (ms) 40013.0\n",
      "Step: 1700 lr: 0.001000 Train loss: 0.10 Test accuracy: 98.6 Time/image (ms) 4741.3\n",
      "Step: 1750 lr: 0.001000 Train loss: 0.09 Test accuracy: 98.8 Time/image (ms) 7915.2\n",
      "Step: 1800 lr: 0.001000 Train loss: 0.06 Test accuracy: 98.9 Time/image (ms) 118950.0\n"
     ]
    }
   ],
   "source": [
    "summary_writer = tf.summary.FileWriter(logdir=log_dir+'/summary/', flush_secs=10)\n",
    "saver = tf.train.Saver(max_to_keep=None)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    t, gen = {}, {}\n",
    "    coord = tf.train.Coordinator()\n",
    "    for phase in ['train', 'test']:\n",
    "        gen[phase] = train_utils.load_data_gen(H=H, jitter=False, phase=phase)\n",
    "        t[phase] = threading.Thread(target=enqueue_thread, \n",
    "                                    args=(sess, coord, enqueue_op[phase], gen[phase], phase))\n",
    "        t[phase].start()\n",
    "    summary_writer.add_graph(sess.graph)\n",
    "    start = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    init_fn = slim.assign_from_checkpoint_fn(\n",
    "        ignore_missing_vars=True,\n",
    "        model_path='data/inception_v1.ckpt', \n",
    "        var_list=slim.get_model_variables('InceptionV1'))\n",
    "    init_fn(sess)\n",
    "    for i in range(max_iter):\n",
    "        adjusted_lr = learning_rate*0.5**max(0,(np.int32(i/lr_step)-2))\n",
    "        if i%display_iter != 0:\n",
    "            sess.run([train_op, loss['train']], feed_dict={lr: adjusted_lr})\n",
    "        else:\n",
    "            if i>0:\n",
    "                dt = (time.time()-start)/batch_size/display_iter\n",
    "            start = time.time()\n",
    "            train_loss, test_accuracy, summaries, _ = sess.run(\n",
    "                [loss['train'], accuracy['test'], summary_op, train_op], feed_dict={lr: adjusted_lr})\n",
    "            summary_writer.add_summary(summaries, global_step=global_step.eval())\n",
    "            print_str = string.join([\n",
    "                'Step: %d',\n",
    "                'lr: %f',\n",
    "                'Train loss: %.2f',\n",
    "                'Test accuracy: %.1f',\n",
    "                'Time/image (ms) %.1f'\n",
    "            ])\n",
    "            print(print_str %(i, adjusted_lr, train_loss, test_accuracy*100, dt*1000 if i>0 else 0))\n",
    "        if global_step.eval() % save_iter ==0 or global_step.eval() == max_iter-1:\n",
    "            saver.save(sess, log_dir+'/checkpoint/', global_step=global_step.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coord.request_stop()\n",
    "coord.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx, yy, zz = sess.run(queue['train'].dequeue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.int32(5.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}